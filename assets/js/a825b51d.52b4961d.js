"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[916],{1901:(n,e,o)=>{o.r(e),o.d(e,{assets:()=>r,contentTitle:()=>l,default:()=>d,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"humanoid-robotics/bipedal-locomotion","title":"Bipedal Locomotion","description":"Teaching a humanoid robot to walk is one of the most challenging and rewarding tasks in robotics. This chapter explores the fundamentals of bipedal locomotion.","source":"@site/docs/humanoid-robotics/bipedal-locomotion.md","sourceDirName":"humanoid-robotics","slug":"/humanoid-robotics/bipedal-locomotion","permalink":"/Physical-AI-Humanoid-Robotics-Course/docs/humanoid-robotics/bipedal-locomotion","draft":false,"unlisted":false,"editUrl":"https://github.com/KulsumShaikh16/Physical-AI-Humanoid-Robotics-Course/tree/main/my-website/docs/humanoid-robotics/bipedal-locomotion.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Humanoid Robotics","permalink":"/Physical-AI-Humanoid-Robotics-Course/docs/category/humanoid-robotics"},"next":{"title":"Computer Vision","permalink":"/Physical-AI-Humanoid-Robotics-Course/docs/perception/computer-vision"}}');var i=o(4848),s=o(8453);const a={sidebar_position:1},l="Bipedal Locomotion",r={},c=[{value:"The Challenge of Walking",id:"the-challenge-of-walking",level:2},{value:"Humanoid Robot Models",id:"humanoid-robot-models",level:2},{value:"Center of Mass and Stability",id:"center-of-mass-and-stability",level:2},{value:"Zero Moment Point (ZMP)",id:"zero-moment-point-zmp",level:2},{value:"Simple Walking Controller",id:"simple-walking-controller",level:2},{value:"Reinforcement Learning for Walking",id:"reinforcement-learning-for-walking",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Practice Exercises",id:"practice-exercises",level:2},{value:"Next Steps",id:"next-steps",level:2}];function p(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"bipedal-locomotion",children:"Bipedal Locomotion"})}),"\n",(0,i.jsx)(e.p,{children:"Teaching a humanoid robot to walk is one of the most challenging and rewarding tasks in robotics. This chapter explores the fundamentals of bipedal locomotion."}),"\n",(0,i.jsx)(e.h2,{id:"the-challenge-of-walking",children:"The Challenge of Walking"}),"\n",(0,i.jsx)(e.p,{children:"Unlike wheeled robots, bipedal robots must:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Maintain Balance"})," while supported by only one or two feet"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Generate Locomotion"})," through coordinated leg movements"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Handle Disturbances"})," and recover from perturbations"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Optimize Energy"})," to walk efficiently"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"humanoid-robot-models",children:"Humanoid Robot Models"}),"\n",(0,i.jsx)(e.p,{children:"Let's work with a simple humanoid in PyBullet:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import pybullet as p\nimport pybullet_data\nimport numpy as np\nimport time\n\n# Setup simulation\np.connect(p.GUI)\np.setAdditionalSearchPath(pybullet_data.getDataPath())\np.setGravity(0, 0, -9.81)\np.setTimeStep(1./240.)\n\n# Load environment\nplane = p.loadURDF("plane.urdf")\n\n# Load humanoid robot\nhumanoid = p.loadURDF("humanoid/humanoid.urdf", [0, 0, 0.9])\n\n# Get joint information\nnum_joints = p.getNumJoints(humanoid)\nprint(f"Humanoid has {num_joints} joints")\n\nfor i in range(num_joints):\n    joint_info = p.getJointInfo(humanoid, i)\n    print(f"Joint {i}: {joint_info[1].decode(\'utf-8\')}, Type: {joint_info[2]}")\n'})}),"\n",(0,i.jsx)(e.h2,{id:"center-of-mass-and-stability",children:"Center of Mass and Stability"}),"\n",(0,i.jsx)(e.p,{children:"The key to walking is keeping the Center of Mass (CoM) over the support polygon:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'def get_center_of_mass(robot_id):\n    """Calculate robot\'s center of mass"""\n    total_mass = 0\n    com_position = np.zeros(3)\n    \n    # Base link\n    base_pos, _ = p.getBasePositionAndOrientation(robot_id)\n    base_mass = p.getDynamicsInfo(robot_id, -1)[0]\n    com_position += np.array(base_pos) * base_mass\n    total_mass += base_mass\n    \n    # All other links\n    num_joints = p.getNumJoints(robot_id)\n    for i in range(num_joints):\n        link_state = p.getLinkState(robot_id, i)\n        link_pos = np.array(link_state[0])\n        link_mass = p.getDynamicsInfo(robot_id, i)[0]\n        \n        com_position += link_pos * link_mass\n        total_mass += link_mass\n    \n    com_position /= total_mass\n    return com_position\n\ndef is_stable(robot_id, support_foot_links):\n    """Check if CoM is over support polygon"""\n    com = get_center_of_mass(robot_id)\n    \n    # Get support foot positions\n    foot_positions = []\n    for link_id in support_foot_links:\n        link_state = p.getLinkState(robot_id, link_id)\n        foot_positions.append(link_state[0][:2])  # Only x, y\n    \n    # Simple check: CoM x,y within convex hull of foot positions\n    # (Simplified - in practice use proper convex hull algorithm)\n    foot_positions = np.array(foot_positions)\n    com_xy = com[:2]\n    \n    return True  # Placeholder for proper stability check\n'})}),"\n",(0,i.jsx)(e.h2,{id:"zero-moment-point-zmp",children:"Zero Moment Point (ZMP)"}),"\n",(0,i.jsx)(e.p,{children:"The ZMP is a crucial concept for bipedal walking:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'def calculate_zmp(robot_id):\n    """\n    Calculate Zero Moment Point\n    ZMP is the point on the ground where total inertial and gravitational\n    forces have zero moment\n    """\n    # Get CoM and its derivatives\n    com = get_center_of_mass(robot_id)\n    # In practice, you\'d calculate CoM velocity and acceleration\n    com_vel = np.zeros(3)  # Placeholder\n    com_acc = np.array([0, 0, -9.81])  # Gravity\n    \n    # ZMP calculation (simplified)\n    # zmp_x = com_x - (com_z / com_acc_z) * com_acc_x\n    # zmp_y = com_y - (com_z / com_acc_z) * com_acc_y\n    \n    if com_acc[2] != 0:\n        zmp_x = com[0] - (com[2] / com_acc[2]) * com_acc[0]\n        zmp_y = com[1] - (com[2] / com_acc[2]) * com_acc[1]\n    else:\n        zmp_x, zmp_y = com[0], com[1]\n    \n    return np.array([zmp_x, zmp_y, 0])\n'})}),"\n",(0,i.jsx)(e.h2,{id:"simple-walking-controller",children:"Simple Walking Controller"}),"\n",(0,i.jsx)(e.p,{children:"Let's implement a basic walking gait:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class SimpleWalkingController:\n    def __init__(self, robot_id):\n        self.robot = robot_id\n        self.phase = 0  # Walking phase\n        self.step_duration = 1.0  # seconds per step\n        self.step_height = 0.05  # meters\n        \n        # Joint indices (example - adjust for your robot)\n        self.left_hip = 2\n        self.left_knee = 3\n        self.left_ankle = 4\n        self.right_hip = 5\n        self.right_knee = 6\n        self.right_ankle = 7\n    \n    def get_joint_targets(self, t):\n        """Calculate target joint angles based on walking phase"""\n        # Sinusoidal gait pattern\n        phase = (t % self.step_duration) / self.step_duration\n        angle = 2 * np.pi * phase\n        \n        # Hip swing\n        hip_angle = 0.3 * np.sin(angle)\n        \n        # Knee bend\n        knee_angle = 0.5 * max(0, np.sin(angle))\n        \n        if phase < 0.5:  # Left leg swing\n            targets = {\n                self.left_hip: hip_angle,\n                self.left_knee: knee_angle,\n                self.left_ankle: -0.1,\n                self.right_hip: -hip_angle * 0.5,\n                self.right_knee: 0,\n                self.right_ankle: -0.1,\n            }\n        else:  # Right leg swing\n            targets = {\n                self.left_hip: -hip_angle * 0.5,\n                self.left_knee: 0,\n                self.left_ankle: -0.1,\n                self.right_hip: hip_angle,\n                self.right_knee: knee_angle,\n                self.right_ankle: -0.1,\n            }\n        \n        return targets\n    \n    def step(self, t):\n        """Execute one control step"""\n        targets = self.get_joint_targets(t)\n        \n        for joint_id, target_angle in targets.items():\n            p.setJointMotorControl2(\n                self.robot,\n                joint_id,\n                controlMode=p.POSITION_CONTROL,\n                targetPosition=target_angle,\n                force=500,\n                maxVelocity=2.0\n            )\n\n# Usage\ncontroller = SimpleWalkingController(humanoid)\n\nfor i in range(5000):\n    t = i / 240.0  # Time in seconds\n    controller.step(t)\n    p.stepSimulation()\n    time.sleep(1./240.)\n'})}),"\n",(0,i.jsx)(e.h2,{id:"reinforcement-learning-for-walking",children:"Reinforcement Learning for Walking"}),"\n",(0,i.jsx)(e.p,{children:"Train a robot to walk using PPO:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import gym\nfrom stable_baselines3 import PPO\n\nclass HumanoidWalkEnv(gym.Env):\n    """Gym environment for humanoid walking"""\n    \n    def __init__(self):\n        super().__init__()\n        \n        # Setup PyBullet\n        self.physics_client = p.connect(p.DIRECT)\n        p.setGravity(0, 0, -9.81)\n        \n        # Load robot\n        self.humanoid = p.loadURDF("humanoid/humanoid.urdf", [0, 0, 0.9])\n        \n        # Define spaces\n        self.action_space = gym.spaces.Box(\n            low=-1, high=1, shape=(8,), dtype=np.float32\n        )\n        self.observation_space = gym.spaces.Box(\n            low=-np.inf, high=np.inf, shape=(44,), dtype=np.float32\n        )\n    \n    def reset(self):\n        p.resetSimulation()\n        p.setGravity(0, 0, -9.81)\n        self.humanoid = p.loadURDF("humanoid/humanoid.urdf", [0, 0, 0.9])\n        return self._get_obs()\n    \n    def _get_obs(self):\n        # Get base position and orientation\n        base_pos, base_orn = p.getBasePositionAndOrientation(self.humanoid)\n        base_vel, base_ang_vel = p.getBaseVelocity(self.humanoid)\n        \n        # Get joint states\n        joint_states = p.getJointStates(self.humanoid, range(8))\n        joint_pos = [state[0] for state in joint_states]\n        joint_vel = [state[1] for state in joint_states]\n        \n        # Combine all observations\n        obs = np.concatenate([\n            base_pos, base_orn, base_vel, base_ang_vel,\n            joint_pos, joint_vel\n        ])\n        return obs.astype(np.float32)\n    \n    def step(self, action):\n        # Apply actions to joints\n        for i, a in enumerate(action):\n            p.setJointMotorControl2(\n                self.humanoid, i,\n                controlMode=p.POSITION_CONTROL,\n                targetPosition=a,\n                force=500\n            )\n        \n        p.stepSimulation()\n        \n        # Get new state\n        obs = self._get_obs()\n        \n        # Calculate reward\n        base_pos, _ = p.getBasePositionAndOrientation(self.humanoid)\n        \n        # Reward forward movement\n        forward_reward = base_pos[0]\n        \n        # Penalty for falling\n        height = base_pos[2]\n        alive_bonus = 1.0 if height > 0.5 else 0\n        \n        # Energy penalty\n        energy_penalty = -0.01 * np.sum(np.square(action))\n        \n        reward = forward_reward + alive_bonus + energy_penalty\n        done = height < 0.5\n        \n        return obs, reward, done, {}\n\n# Train the agent\nenv = HumanoidWalkEnv()\nmodel = PPO("MlpPolicy", env, verbose=1)\nmodel.learn(total_timesteps=1000000)\nmodel.save("humanoid_walk")\n'})}),"\n",(0,i.jsx)(e.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Static Stability"})," \u2013 CoM always over support polygon (slow but stable)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Dynamic Stability"})," \u2013 ZMP-based control (allows faster walking)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Gait Patterns"})," \u2013 Coordinated sequences of leg movements"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Balance Recovery"})," \u2013 Responding to external disturbances"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"practice-exercises",children:"Practice Exercises"}),"\n",(0,i.jsx)(e.admonition,{title:"Exercise 1: Analyze Stability",type:"tip",children:(0,i.jsx)(e.p,{children:"Implement a real-time visualization of the CoM and support polygon during walking."})}),"\n",(0,i.jsx)(e.admonition,{title:"Exercise 2: Improve Gait",type:"tip",children:(0,i.jsx)(e.p,{children:"Modify the walking controller to include ankle and hip strategies for better balance."})}),"\n",(0,i.jsx)(e.admonition,{title:"Exercise 3: RL Experiment",type:"tip",children:(0,i.jsx)(e.p,{children:"Train a humanoid to walk backwards or sideways using reinforcement learning."})}),"\n",(0,i.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(e.p,{children:["Ready to add intelligence? Learn about ",(0,i.jsx)(e.a,{href:"/Physical-AI-Humanoid-Robotics-Course/docs/perception/computer-vision",children:"computer vision for robotics"})," to give your robot eyes!"]})]})}function d(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(p,{...n})}):p(n)}},8453:(n,e,o)=>{o.d(e,{R:()=>a,x:()=>l});var t=o(6540);const i={},s=t.createContext(i);function a(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:a(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);